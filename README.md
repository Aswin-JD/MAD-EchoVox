**Echo Vox**

Echo Vox is an innovative project aimed at bridging the communication gap for individuals who are deaf or hard of hearing. This project leverages Mediapipe, a powerful library for real-time hand and body tracking, to recognize sign language gestures without the need for complex convolutional neural networks (CNNs).

By focusing on lightweight and efficient algorithms, Echo Vox delivers real-time sign language recognition that is accessible, scalable, and effective, making it a valuable tool for promoting inclusive communication in various settings such as education, workplaces, and daily interactions.

*Key Features*
No CNN Approach: Achieves recognition without requiring deep neural networks, ensuring fast and efficient processing.
Powered by Mediapipe: Utilizes state-of-the-art Mediapipe for accurate hand landmark detection and gesture analysis.
Real-Time Recognition: Enables seamless and instant sign language interpretation.
Accessible and Lightweight: Designed to work on devices with limited computational resources.

*Goals*
To create a user-friendly tool for real-time sign language recognition.
To promote inclusivity and accessibility for deaf and mute individuals.
To develop a solution that is lightweight, open-source, and adaptable to various languages and gestures
